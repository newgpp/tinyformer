# tinyformer

A tiny but complete Transformer (Encoder + Decoder) implemented from scratch in Python 3.12 + PyTorch.

Goal:
- Understand Q/K/V
- Understand attention masks
- Understand encoder-decoder cross attention
- Train on toy tasks like copy / reverse / translate

This is not about SOTA.
This is about **understanding the architecture**.
